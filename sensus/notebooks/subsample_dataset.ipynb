{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sensus import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of the dataset to sumsample\n",
    "p = 0.25\n",
    "assert 0 < p < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(data.__path__[0], 'DAIR-V2X',\n",
    "    'cooperative-vehicle-infrastructure-kittiformat', 'infrastructure-side')\n",
    "new_dataset_path = os.path.join(data.__path__[0], 'DAIR-V2X',\n",
    "    f'cooperative-vehicle-infrastructure-kittiformat-sub{int(p*100)}', \n",
    "    'infrastructure-side')\n",
    "\n",
    "dirs_to_copy = ['ImageSets', 'training', 'testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_name in dirs_to_copy:\n",
    "    os.makedirs(os.path.join(new_dataset_path, dir_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        files = f.readlines()\n",
    "        files = [f.strip() for f in files]\n",
    "        files.sort()\n",
    "    return files\n",
    "\n",
    "train_txt = os.path.join(dataset_path, 'ImageSets', 'train.txt')\n",
    "val_txt = os.path.join(dataset_path, 'ImageSets', 'val.txt')\n",
    "trainval_txt = os.path.join(dataset_path, 'ImageSets', 'trainval.txt')\n",
    "test_txt = os.path.join(dataset_path, 'ImageSets', 'test.txt')\n",
    "\n",
    "train_files = read_txt_file(train_txt)\n",
    "val_files = read_txt_file(val_txt)\n",
    "trainval_files = read_txt_file(trainval_txt)\n",
    "test_files = read_txt_file(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the trainval set is the union of the train and val sets\n",
    "train_set = set(train_files)\n",
    "val_set = set(val_files)\n",
    "trainval_set = train_set.union(val_set)\n",
    "trainval_set = list(trainval_set)\n",
    "trainval_set.sort()\n",
    "assert trainval_set == trainval_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample each set randomly\n",
    "import random\n",
    "random.seed(47)\n",
    "\n",
    "new_train_files = random.sample(train_files, int(p*len(train_files)))\n",
    "new_val_files = random.sample(val_files, int(p*len(val_files)))\n",
    "new_test_files = random.sample(test_files, int(p*len(test_files)))\n",
    "new_train_files.sort()\n",
    "new_val_files.sort()\n",
    "new_test_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainval_files = set(new_train_files).union(set(new_val_files))\n",
    "new_trainval_files = list(new_trainval_files)\n",
    "new_trainval_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt_file(file_path, files):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for file in files:\n",
    "            f.write(file + '\\n')\n",
    "\n",
    "save_txt_file(os.path.join(new_dataset_path, 'ImageSets', 'train.txt'), new_train_files)\n",
    "save_txt_file(os.path.join(new_dataset_path, 'ImageSets', 'val.txt'), new_val_files)\n",
    "save_txt_file(os.path.join(new_dataset_path, 'ImageSets', 'trainval.txt'), new_trainval_files)\n",
    "save_txt_file(os.path.join(new_dataset_path, 'ImageSets', 'test.txt'), new_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = os.path.join(dataset_path, 'training')\n",
    "testing_path = os.path.join(dataset_path, 'testing')\n",
    "new_training_path = os.path.join(new_dataset_path, 'training')\n",
    "new_testing_path = os.path.join(new_dataset_path, 'testing')\n",
    "\n",
    "def copy_files(files, src_dir, dst_dir):\n",
    "    print(f'Copying {len(files)} files from {src_dir.split(\"/\")[-1]} to {dst_dir.split(\"/\")[-1]}')\n",
    "    for file in tqdm(files):\n",
    "        src_file = os.path.join(src_dir, file)\n",
    "        dst_file = os.path.join(dst_dir, file)\n",
    "        os.system(f'cp {src_file} {dst_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2200 files from velodyne to velodyne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:09<00:00, 233.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 906 files from velodyne to velodyne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 906/906 [00:04<00:00, 206.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2200 files from image_2 to image_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:10<00:00, 210.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 906 files from image_2 to image_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 906/906 [00:04<00:00, 194.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2200 files from velodyne_reduced to velodyne_reduced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:11<00:00, 189.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 906 files from velodyne_reduced to velodyne_reduced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 906/906 [00:04<00:00, 223.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2200 files from calib to calib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:07<00:00, 305.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 906 files from calib to calib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 906/906 [00:03<00:00, 295.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 2200 files from label_2 to label_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:07<00:00, 283.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 906 files from label_2 to label_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 906/906 [00:02<00:00, 310.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for each_dir in os.listdir(training_path):\n",
    "    src_dir = os.path.join(training_path, each_dir)\n",
    "    dst_dir = os.path.join(new_training_path, each_dir)\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    src_files = os.listdir(src_dir)\n",
    "    src_files.sort()\n",
    "    # Get extension of the files\n",
    "    ext = os.path.splitext(src_files[0])[1]\n",
    "    new_train_files_wext = [f + ext for f in new_train_files]\n",
    "    new_val_files_wext = [f + ext for f in new_val_files]\n",
    "\n",
    "    copy_files(new_train_files_wext, src_dir, dst_dir)\n",
    "    copy_files(new_val_files_wext, src_dir, dst_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

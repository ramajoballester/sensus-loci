{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sensus\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "from sensus.utils.data_converter import pc2pc_object\n",
    "from open3d.web_visualizer import draw\n",
    "# from mmdetection3d import data, demo, configs, checkpoints\n",
    "from sensus import configs as sensus_configs\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/messi/anaconda3/envs/sensus/bin:/home/messi/.local/bin:/usr/local/google-cloud-sdk/bin:/home/messi/ros2_humble/install/rviz2/bin:/home/messi/ros2_humble/install/rqt_bag/bin:/home/messi/ros2_humble/install/urdfdom/bin:/home/messi/ros2_humble/install/rqt_graph/bin:/home/messi/ros2_humble/install/rqt_gui/bin:/home/messi/ros2_humble/install/ros2cli/bin:/home/messi/ros2_humble/install/ament_uncrustify/bin:/home/messi/ros2_humble/install/uncrustify_vendor/bin:/home/messi/ros2_humble/install/pendulum_control/bin:/home/messi/ros2_humble/install/tlsf_cpp/bin:/home/messi/ros2_humble/install/rttest/bin:/home/messi/ros2_humble/install/rosidl_cli/bin:/home/messi/ros2_humble/install/launch_testing/bin:/home/messi/ros2_humble/install/cyclonedds/bin:/home/messi/ros2_humble/install/iceoryx_posh/bin:/home/messi/ros2_humble/install/fastrtps/bin:/home/messi/ros2_humble/install/foonathan_memory_vendor/bin:/home/messi/ros2_humble/install/ament_xmllint/bin:/home/messi/ros2_humble/install/ament_pyflakes/bin:/home/messi/ros2_humble/install/ament_pycodestyle/bin:/home/messi/ros2_humble/install/ament_pep257/bin:/home/messi/ros2_humble/install/ament_pclint/bin:/home/messi/ros2_humble/install/ament_mypy/bin:/home/messi/ros2_humble/install/ament_lint_cmake/bin:/home/messi/ros2_humble/install/ament_flake8/bin:/home/messi/ros2_humble/install/ament_copyright/bin:/home/messi/ros2_humble/install/ament_index_python/bin:/home/messi/ros2_humble/install/ament_cpplint/bin:/home/messi/ros2_humble/install/ament_cppcheck/bin:/home/messi/ros2_humble/install/ament_clang_tidy/bin:/home/messi/ros2_humble/install/ament_clang_format/bin:/home/messi/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda-11.1/bin\n"
     ]
    }
   ],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin:/home/messi/.vscode-server/bin/f1b07bd25dfad64b0167beb15359ae573aecd2cc/bin/remote-cli:/home/messi/.local/bin:/usr/local/google-cloud-sdk/bin:/home/messi/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda-11.1/bin:/home/messi/.vscode-server/bin/f1b07bd25dfad64b0167beb15359ae573aecd2cc/bin/remote-cli:/home/messi/.local/bin:/usr/local/google-cloud-sdk/bin:/home/messi/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda-11.1/bin\n"
     ]
    }
   ],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sensor_msgs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pickle file lidar.pickle from data directory\n",
    "with open(os.path.join(sensus.__path__[0], 'data/lidar.pickle'), 'rb') as f:\n",
    "    lidar_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_buffer = np.frombuffer(lidar_pickle.data,\n",
    "                    dtype=[('x', np.float32), ('y', np.float32), ('z', np.float32), ('intensity', np.float32)],\n",
    "                    count=lidar_pickle.width*lidar_pickle.height, offset=0)\n",
    "pc_ros = pc_buffer.view(dtype=np.float32).reshape(pc_buffer.shape[0], -1)\n",
    "pc_ros[:, 2] = pc_ros[:, 2] + 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet3d.apis import inference_detector, init_model\n",
    "from mmdet3d.utils import register_all_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/messi/alvaro/sensus-loci/sensus/../mmdetection3d/checkpoints/centerpoint_0075voxel_second_secfpn_circlenms_4x8_cyclic_20e_nus_20220810_011659-04cb3a3b.pth\n"
     ]
    }
   ],
   "source": [
    "register_all_modules()\n",
    "# model_cfg = os.path.join(sensus_configs.__path__[0],\n",
    "#     'second/second_hv_secfpn_8xb6-80e_kitti-3d-3class-ros.py')\n",
    "model_cfg = os.path.join(sensus.__path__[0], '../mmdetection3d/configs',\n",
    "    'centerpoint/centerpoint_voxel0075_second_secfpn_head-circlenms_8xb4-cyclic-20e_nus-3d.py')\n",
    "# checkpoint_path = os.path.join(checkpoints.__path__[0],\n",
    "#     'hv_second_secfpn_6x8_80e_kitti-3d-3class_20210831_022017-ae782e87.pth')\n",
    "checkpoint_path = os.path.join(sensus.__path__[0], '../mmdetection3d/checkpoints',\n",
    "    'centerpoint_0075voxel_second_secfpn_circlenms_4x8_cyclic_20e_nus_20220810_011659-04cb3a3b.pth')\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = init_model(model_cfg, checkpoint_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115.05504    115.06092     -0.7852335    0.95542234]\n",
      "[-116.592995   -115.0505       -4.008335      0.61992574]\n"
     ]
    }
   ],
   "source": [
    "# Print the max and min values of each column in the point cloud\n",
    "print(np.max(pc_ros, axis=0))\n",
    "print(np.min(pc_ros, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'LoadPointsFromFile',\n",
       "  'coord_type': 'LIDAR',\n",
       "  'load_dim': 4,\n",
       "  'use_dim': 5},\n",
       " {'type': 'LoadPointsFromMultiSweeps',\n",
       "  'sweeps_num': 9,\n",
       "  'use_dim': [0, 1, 2, 3],\n",
       "  'pad_empty_sweeps': True,\n",
       "  'remove_close': True},\n",
       " {'type': 'MultiScaleFlipAug3D',\n",
       "  'img_scale': (1333, 800),\n",
       "  'pts_scale_ratio': 1,\n",
       "  'flip': False,\n",
       "  'transforms': [{'type': 'GlobalRotScaleTrans',\n",
       "    'rot_range': [0, 0],\n",
       "    'scale_ratio_range': [1.0, 1.0],\n",
       "    'translation_std': [0, 0, 0]},\n",
       "   {'type': 'RandomFlip3D'},\n",
       "   {'type': 'PointsRangeFilter',\n",
       "    'point_cloud_range': [-54, -54, -5.0, 54, 54, 3.0]}]},\n",
       " {'type': 'Pack3DDetInputs', 'keys': ['points']}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg.test_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'LiDARPoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/messi/alvaro/sensus-loci/sensus/notebooks/ros.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Buc3m_server/home/messi/alvaro/sensus-loci/sensus/notebooks/ros.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# ROS\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Buc3m_server/home/messi/alvaro/sensus-loci/sensus/notebooks/ros.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m pc_object_ros, _ \u001b[39m=\u001b[39m pc2pc_object(pc_ros\u001b[39m.\u001b[39mflatten(), model\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mtest_pipeline)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Buc3m_server/home/messi/alvaro/sensus-loci/sensus/notebooks/ros.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m result_ros, _ \u001b[39m=\u001b[39m inference_detector(model, pc_object_ros)\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus/lib/python3.8/site-packages/mmdet3d/apis/inference.py:175\u001b[0m, in \u001b[0;36minference_detector\u001b[0;34m(model, pcds)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m         \u001b[39m# directly use loaded point cloud\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         data_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    169\u001b[0m             points\u001b[39m=\u001b[39mpcd,\n\u001b[1;32m    170\u001b[0m             timestamp\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m             box_type_3d\u001b[39m=\u001b[39mbox_type_3d,\n\u001b[1;32m    174\u001b[0m             box_mode_3d\u001b[39m=\u001b[39mbox_mode_3d)\n\u001b[0;32m--> 175\u001b[0m     data_ \u001b[39m=\u001b[39m test_pipeline(data_)\n\u001b[1;32m    176\u001b[0m     data\u001b[39m.\u001b[39mappend(data_)\n\u001b[1;32m    178\u001b[0m collate_data \u001b[39m=\u001b[39m pseudo_collate(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py:58\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 58\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     59\u001b[0m     \u001b[39m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus/lib/python3.8/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(results)\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus/lib/python3.8/site-packages/mmdet3d/datasets/transforms/loading.py:742\u001b[0m, in \u001b[0;36mLoadPointsFromDict.transform\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    734\u001b[0m     attribute_dims\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m    735\u001b[0m         \u001b[39mdict\u001b[39m(color\u001b[39m=\u001b[39m[\n\u001b[1;32m    736\u001b[0m             points\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m3\u001b[39m,\n\u001b[1;32m    737\u001b[0m             points\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[1;32m    738\u001b[0m             points\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m    739\u001b[0m         ]))\n\u001b[1;32m    741\u001b[0m points_class \u001b[39m=\u001b[39m get_points_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoord_type)\n\u001b[0;32m--> 742\u001b[0m points \u001b[39m=\u001b[39m points_class(\n\u001b[1;32m    743\u001b[0m     points, points_dim\u001b[39m=\u001b[39;49mpoints\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], attribute_dims\u001b[39m=\u001b[39;49mattribute_dims)\n\u001b[1;32m    744\u001b[0m results[\u001b[39m'\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m points\n\u001b[1;32m    745\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus/lib/python3.8/site-packages/mmdet3d/structures/points/lidar_points.py:34\u001b[0m, in \u001b[0;36mLiDARPoints.__init__\u001b[0;34m(self, tensor, points_dim, attribute_dims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     31\u001b[0m              tensor: Union[Tensor, np\u001b[39m.\u001b[39mndarray, Sequence[Sequence[\u001b[39mfloat\u001b[39m]]],\n\u001b[1;32m     32\u001b[0m              points_dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m,\n\u001b[1;32m     33\u001b[0m              attribute_dims: Optional[\u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[39msuper\u001b[39;49m(LiDARPoints, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     35\u001b[0m         tensor, points_dim\u001b[39m=\u001b[39;49mpoints_dim, attribute_dims\u001b[39m=\u001b[39;49mattribute_dims)\n\u001b[1;32m     36\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrotation_axis \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus/lib/python3.8/site-packages/mmdet3d/structures/points/base_points.py:41\u001b[0m, in \u001b[0;36mBasePoints.__init__\u001b[0;34m(self, tensor, points_dim, attribute_dims)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mas_tensor(tensor, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m tensor\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     43\u001b[0m     \u001b[39m# Use reshape, so we don't end up creating a new tensor that does\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39m# not depend on the inputs (and consequently confuses jit)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     tensor \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, points_dim))\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'LiDARPoints'"
     ]
    }
   ],
   "source": [
    "# ROS\n",
    "pc_object_ros, _ = pc2pc_object(pc_ros.flatten(), model.cfg.test_pipeline)\n",
    "result_ros, _ = inference_detector(model, pc_object_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_ros' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/messi/alvaro/sensus-loci/sensus/notebooks/ros.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Buc3m_server/home/messi/alvaro/sensus-loci/sensus/notebooks/ros.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mtype\u001b[39m(result_ros)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_ros' is not defined"
     ]
    }
   ],
   "source": [
    "type(result_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.506675720214844, 28.6533203125, -3.9237818717956543, 4.577454566955566, 1.8992881774902344, 1.6064486503601074, 2.5990734100341797, -2.3876028060913086, 2.019270181655884]\n",
      "0.8311319351196289\n"
     ]
    }
   ],
   "source": [
    "for i, bbox_pred in enumerate(result_ros.pred_instances_3d.bboxes_3d.tensor.tolist()):\n",
    "    print(bbox_pred)\n",
    "    print(result_ros.pred_instances_3d.scores_3d[i].item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ros.pred_instances_3d.labels_3d.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([-32.6744, -36.7824,  -4.2120,   0.4797,   0.7362,   0.8834,  -3.0265,\n",
       "         -7.6658,  -9.6750], device='cuda:0'),\n",
       "indices=tensor([ 4, 17, 10, 22, 23, 21, 19, 11,  7], device='cuda:0'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ros.pred_instances_3d.bboxes_3d.tensor.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([37.5542, 31.8943,  0.0938, 17.5359,  3.1787,  4.2872,  3.1106,  6.4032,\n",
       "         6.4455], device='cuda:0'),\n",
       "indices=tensor([20, 10, 23, 20, 21, 20, 21, 15,  3], device='cuda:0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_ros.pred_instances_3d.bboxes_3d.tensor.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1.6682, -37.9861,  -2.6241,   4.3703,   1.7161,   1.5333,   3.2115],\n",
      "       device='cuda:0')\n",
      "torch.Size([18, 7])\n"
     ]
    }
   ],
   "source": [
    "# print(result_ros.pred_instances_3d.labels_3d)\n",
    "# print(result_ros.pred_instances_3d.scores_3d)\n",
    "# print(result_ros.pred_instances_3d.bboxes_3d)\n",
    "print(result_ros.pred_instances_3d.bboxes_3d.tensor[0])\n",
    "print(result_ros.pred_instances_3d.bboxes_3d.tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'rotate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Same result after processing points (maybe processing under the hood when\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# using np.array pc)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m points \u001b[39m=\u001b[39m points\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m result, data \u001b[39m=\u001b[39m inference_detector(model, points)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/apis/inference.py:158\u001b[0m, in \u001b[0;36minference_detector\u001b[0;34m(model, pcds)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[39m# directly use loaded point cloud\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         data_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    152\u001b[0m             points\u001b[39m=\u001b[39mpcd,\n\u001b[1;32m    153\u001b[0m             timestamp\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m             box_type_3d\u001b[39m=\u001b[39mbox_type_3d,\n\u001b[1;32m    157\u001b[0m             box_mode_3d\u001b[39m=\u001b[39mbox_mode_3d)\n\u001b[0;32m--> 158\u001b[0m     data_ \u001b[39m=\u001b[39m test_pipeline(data_)\n\u001b[1;32m    159\u001b[0m     data\u001b[39m.\u001b[39mappend(data_)\n\u001b[1;32m    161\u001b[0m collate_data \u001b[39m=\u001b[39m pseudo_collate(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py:58\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 58\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     59\u001b[0m     \u001b[39m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(results)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/test_time_aug.py:109\u001b[0m, in \u001b[0;36mMultiScaleFlipAug3D.transform\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    105\u001b[0m                         _results[\u001b[39m'\u001b[39m\u001b[39mpcd_horizontal_flip\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[1;32m    106\u001b[0m                             pcd_horizontal_flip\n\u001b[1;32m    107\u001b[0m                         _results[\u001b[39m'\u001b[39m\u001b[39mpcd_vertical_flip\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \\\n\u001b[1;32m    108\u001b[0m                             pcd_vertical_flip\n\u001b[0;32m--> 109\u001b[0m                         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms(_results)\n\u001b[1;32m    110\u001b[0m                         aug_data_list\u001b[39m.\u001b[39mappend(data)\n\u001b[1;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m aug_data_list\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmengine/dataset/base_dataset.py:58\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m   dict: Transformed data.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 58\u001b[0m     data \u001b[39m=\u001b[39m t(data)\n\u001b[1;32m     59\u001b[0m     \u001b[39m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[39m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensus_1.1/lib/python3.8/site-packages/mmcv/transforms/base.py:12\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m              results: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(results)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/transforms_3d.py:782\u001b[0m, in \u001b[0;36mGlobalRotScaleTrans.transform\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtransformation_3d_flow\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m input_dict:\n\u001b[1;32m    780\u001b[0m     input_dict[\u001b[39m'\u001b[39m\u001b[39mtransformation_3d_flow\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rot_bbox_points(input_dict)\n\u001b[1;32m    784\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mpcd_scale_factor\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m input_dict:\n\u001b[1;32m    785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_random_scale(input_dict)\n",
      "File \u001b[0;32m~/alvaro/sensus-loci/mmdetection3d/mmdet3d/datasets/transforms/transforms_3d.py:725\u001b[0m, in \u001b[0;36mGlobalRotScaleTrans._rot_bbox_points\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    722\u001b[0m     input_dict[\u001b[39m'\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m points\n\u001b[1;32m    723\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     \u001b[39m# if no bbox in input_dict, only rotate points\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     rot_mat_T \u001b[39m=\u001b[39m input_dict[\u001b[39m'\u001b[39;49m\u001b[39mpoints\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mrotate(noise_rotation)\n\u001b[1;32m    727\u001b[0m input_dict[\u001b[39m'\u001b[39m\u001b[39mpcd_rotation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m rot_mat_T\n\u001b[1;32m    728\u001b[0m input_dict[\u001b[39m'\u001b[39m\u001b[39mpcd_rotation_angle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m noise_rotation\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'rotate'"
     ]
    }
   ],
   "source": [
    "# Same result after processing points (maybe processing under the hood when\n",
    "# using np.array pc)\n",
    "points = points.reshape(-1, 4)\n",
    "result, data = inference_detector(model, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "tensor([0.1304, 0.1173, 0.3624, 0.3572, 0.9088, 0.8917, 0.8498, 0.7471, 0.7245,\n",
      "        0.6414, 0.6307, 0.5603, 0.4316, 0.3937], device='cuda:0')\n",
      "torch.Size([14, 7])\n"
     ]
    }
   ],
   "source": [
    "print(result.pred_instances_3d.labels_3d)\n",
    "print(result.pred_instances_3d.scores_3d)\n",
    "print(result.pred_instances_3d.bboxes_3d.tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_path = os.path.join(sensus.__path__[0], '../mmdetection3d/demo',\n",
    "    'data/kitti/000008.bin')\n",
    "pc_path = os.path.join(\n",
    "    '/home/messi/alvaro/sensus-loci/mmdetection3d/demo/kitti_pointpillars/kitti_000008',\n",
    "    'kitti_000008_points.obj')\n",
    "bboxes_path = os.path.join(\n",
    "    '/home/messi/alvaro/sensus-loci/mmdetection3d/demo/kitti_pointpillars/kitti_000008',\n",
    "    'kitti_000008_pred.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 17238 points.\n"
     ]
    }
   ],
   "source": [
    "# Read pc from bin file\n",
    "with open(bin_path, 'rb') as f:\n",
    "    points = np.fromfile(f, dtype=np.float32, count=-1).reshape([-1, 4])\n",
    "\n",
    "pcd_bin = o3d.geometry.PointCloud()\n",
    "pcd_bin.points = o3d.utility.Vector3dVector(points[:, :3])\n",
    "print(pcd_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 16897 points.\n",
      "LineSet with 180 lines.\n"
     ]
    }
   ],
   "source": [
    "# Read pc from obj file (reading with o3d.io.read_triangle_mesh or \n",
    "# read_point_cloud does not work)\n",
    "pc = []\n",
    "with open(pc_path, 'rb') as f:\n",
    "    for each in f.readlines():\n",
    "        p1, p2, p3 = each.decode('utf-8').split(' ')[1:]\n",
    "        pc.append([float(p1), float(p2), float(p3.replace('\\n', ''))])\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.array(pc))\n",
    "print(pcd)\n",
    "\n",
    "bboxes = o3d.io.read_triangle_mesh(bboxes_path)\n",
    "bboxes.compute_vertex_normals()     # For solid rendering with lighting\n",
    "bboxes_lines = o3d.geometry.LineSet().create_from_triangle_mesh(bboxes)\n",
    "bboxes_lines.paint_uniform_color([1, 0, 0])\n",
    "print(bboxes_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_0 created.\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "[Open3D INFO] ICE servers: {\"stun:stun.l.google.com:19302\", \"turn:user:password@34.69.27.100:3478\", \"turn:user:password@34.69.27.100:3478?transport=tcp\"}\n",
      "FEngine (64 bits) created at 0x7fe9b0008410 (threading is enabled)\n",
      "[Open3D INFO] Set WEBRTC_STUN_SERVER environment variable add a customized WebRTC STUN server.\n",
      "[Open3D INFO] WebRTC Jupyter handshake mode enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8264ef5c2070499c95108fe60229ab7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([pcd, bboxes_lines], width=900, height=600, point_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_1 created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98e944cc3974a0f9fbfed416ce4446e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw([pcd_bin, bboxes_lines], width=900, height=600, point_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from open3d.web_visualizer import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_0 created.\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "[Open3D INFO] ICE servers: [\"stun:stun.l.google.com:19302\", \"turn:user:password@34.69.27.100:3478\", \"turn:user:password@34.69.27.100:3478?transport=tcp\"]\n",
      "FEngine (64 bits) created at 0x7eff0050f010 (threading is enabled)\n",
      "[Open3D INFO] Set WEBRTC_STUN_SERVER environment variable add a customized WebRTC STUN server.\n",
      "[Open3D INFO] WebRTC Jupyter handshake mode enabled.\n",
      "EGL(1.5)\n",
      "OpenGL(4.1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6419c9c403b54d24b071da9183659337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cube_red = o3d.geometry.TriangleMesh.create_box(1, 2, 4)\n",
    "cube_red.compute_vertex_normals()\n",
    "cube_red.paint_uniform_color((1.0, 0.0, 0.0))\n",
    "draw(cube_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_1 created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab168c068014a2fa93373e3d54f3f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cube_blue = o3d.geometry.TriangleMesh.create_box(1, 2, 4)\n",
    "cube_blue.compute_vertex_normals()\n",
    "cube_blue.paint_uniform_color((0.0, 0.0, 1.0))\n",
    "draw(cube_blue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "f415ed57821a0a57975d366e83fa539ca7287180412c6dde381c2f215d5e4022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
